{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b30853f-88c4-4224-99a1-10005858f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "##############################################\n",
    "# 1) Load model & artifacts\n",
    "##############################################\n",
    "\n",
    "with open(\"xgb_carpark_best_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"le_area.pkl\", \"rb\") as f:\n",
    "    le_area = pickle.load(f)\n",
    "\n",
    "with open(\"le_agency.pkl\", \"rb\") as f:\n",
    "    le_agency = pickle.load(f)\n",
    "\n",
    "with open(\"carpark_id_list.pkl\", \"rb\") as f:\n",
    "    distinct_carpark_ids = pickle.load(f)\n",
    "\n",
    "# Also load the columns used during training\n",
    "# so we can reindex at the end\n",
    "with open(\"training_feature_columns.pkl\", \"rb\") as f:\n",
    "    training_feature_columns = pickle.load(f)\n",
    "\n",
    "\n",
    "# load carparkavail data\n",
    "# specify the data type\n",
    "dtype_spec = {\n",
    "    'carpark_id': 'string',\n",
    "    'area': 'category',\n",
    "    'development': 'category',\n",
    "    'location': 'string',\n",
    "    'available_lots': 'int',\n",
    "    'lot_type': 'category',\n",
    "    'agency': 'category',\n",
    "    'source': 'category',\n",
    "    'update_datetime': 'string',\n",
    "}\n",
    "\n",
    "df_avail = pd.read_csv(r\"C:\\Users\\user\\Documents\\Semester 3\\raw_carpark_avail_020325_290325.csv\",\n",
    "                            dtype=dtype_spec, parse_dates=['timestamp'])\n",
    "\n",
    "carpark_info_df = pd.read_csv(r\"C:\\Users\\user\\Documents\\Semester 3\\carpark_information.csv\")\n",
    "carpark_info_df['carpark_id'] = carpark_info_df['carpark_id'].astype(str)\n",
    "carpark_info_df = carpark_info_df.dropna(subset=['area'])\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 1) Simple helper to check df_avail for (carpark_id, same date + hour).\n",
    "###############################################################################\n",
    "def check_df_for_availability(carpark_id: str, ts: pd.Timestamp) -> float:\n",
    "    \"\"\"\n",
    "    Look in df_avail for the same *date* and *hour* as `ts`,\n",
    "    ignoring minutes and seconds. If multiple rows exist in that hour,\n",
    "    we pick the latest one (row with the maximum timestamp).\n",
    "    \"\"\"\n",
    "    # Filter by carpark_id, year-month-day, and hour\n",
    "    mask = (\n",
    "        (df_avail['carpark_id'] == carpark_id)\n",
    "        & (df_avail['timestamp'].dt.date == ts.date())\n",
    "        & (df_avail['timestamp'].dt.hour == ts.hour)\n",
    "    )\n",
    "    subset = df_avail[mask]\n",
    "\n",
    "    if not subset.empty:\n",
    "        # We might pick the last row (highest timestamp) in that hour\n",
    "        row = subset.loc[subset['timestamp'].idxmax()]\n",
    "        return float(row['available_lots'])\n",
    "    return None\n",
    "\n",
    "###############################################################################\n",
    "# 2) Carpark info lookup\n",
    "###############################################################################\n",
    "def get_carpark_info(carpark_id: str):\n",
    "    row = carpark_info_df[carpark_info_df['carpark_id'] == carpark_id]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"No info found for carpark_id={carpark_id}\")\n",
    "    return (\n",
    "        row.iloc[0]['area'],\n",
    "        row.iloc[0]['agency'],\n",
    "        row.iloc[0]['total_lots']\n",
    "    )\n",
    "\n",
    "def safe_label_transform(encoder, label):\n",
    "    try:\n",
    "        return encoder.transform([label])[0]\n",
    "    except ValueError:\n",
    "        return 0  # fallback\n",
    "\n",
    "###############################################################################\n",
    "# 3) Build single-row feature vector\n",
    "###############################################################################\n",
    "def build_feature_vector(\n",
    "    carpark_id: str,\n",
    "    ts: pd.Timestamp,\n",
    "    lag_24: float,\n",
    ") -> pd.DataFrame:\n",
    "    hour = ts.hour\n",
    "    day_of_week = ts.weekday()\n",
    "    is_weekend = 1 if day_of_week in [5, 6] else 0\n",
    "\n",
    "    area, agency, total_lots = get_carpark_info(carpark_id)\n",
    "    area_encoded = safe_label_transform(le_area, area)\n",
    "    agency_encoded = safe_label_transform(le_agency, agency)\n",
    "\n",
    "    row_dict = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': day_of_week,\n",
    "        'is_weekend': is_weekend,\n",
    "        'total_lots': total_lots,\n",
    "        'area_encoded': area_encoded,\n",
    "        'agency_encoded': agency_encoded,\n",
    "        'lag_24': lag_24,\n",
    "    }\n",
    "\n",
    "    # One-hot for carpark_id\n",
    "    for cp in distinct_carpark_ids:\n",
    "        row_dict[f'carpark_{cp}'] = int(cp == carpark_id)\n",
    "\n",
    "    X_row = pd.DataFrame([row_dict])\n",
    "    # Reindex columns exactly as training\n",
    "    X_row = X_row.reindex(columns=training_feature_columns, fill_value=0)\n",
    "    return X_row\n",
    "\n",
    "###############################################################################\n",
    "# 4) Modified lag_24: only consider the same hour on the previous day\n",
    "###############################################################################\n",
    "def get_lag_24_value(\n",
    "    carpark_id: str,\n",
    "    ts: pd.Timestamp,\n",
    "    recursion_depth=0,\n",
    "    max_depth=1\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    1) Round ts down to the hour (ignoring minute/second).\n",
    "    2) Subtract 1 day to find 'same hour' on the previous day.\n",
    "    3) If not found in df_avail, optionally predict that older time\n",
    "       (recursion), else fallback 0.\n",
    "    \"\"\"\n",
    "    # Rounding the current timestamp down to hour\n",
    "    ts_hour = ts.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "    # Move 1 day back, keeping the same hour\n",
    "    t_past = ts_hour - timedelta(days=1)\n",
    "\n",
    "    val = check_df_for_availability(carpark_id, t_past)\n",
    "    if val is not None:\n",
    "        return val\n",
    "\n",
    "    if recursion_depth < max_depth:\n",
    "        # Attempt to predict that older hour if not found\n",
    "        return predict_availability(\n",
    "            carpark_id,\n",
    "            t_past.isoformat(),\n",
    "            recursion_depth=recursion_depth + 1,\n",
    "            max_depth=max_depth\n",
    "        )\n",
    "    else:\n",
    "        # Fallback if older hour not found or predicted\n",
    "        return 0.0\n",
    "\n",
    "###############################################################################\n",
    "# 5) Final Predict Function (Single-Row)\n",
    "###############################################################################\n",
    "def predict_availability(\n",
    "    carpark_id: str,\n",
    "    ts_str: str,\n",
    "    recursion_depth=0,\n",
    "    max_depth=1\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Predict availability for one car park at a given timestamp,\n",
    "    returning an integer (rounded) result.\n",
    "    \"\"\"\n",
    "    ts = pd.to_datetime(ts_str)\n",
    "\n",
    "    # 1) Compute lag_24\n",
    "    lag_24_val = get_lag_24_value(\n",
    "        carpark_id,\n",
    "        ts,\n",
    "        recursion_depth=recursion_depth,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "\n",
    "    # 2) Build one-row feature vector\n",
    "    X_row = build_feature_vector(carpark_id, ts, lag_24_val)\n",
    "\n",
    "    # 3) Call the model's predict method\n",
    "    pred = model.predict(X_row)\n",
    "\n",
    "    # 4) Round and convert to int\n",
    "    return int(round(float(pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1783bb1-a175-4a6f-b9fe-1d9d6f2d09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted availability for U58 at 2025-03-29 13:00:00: 573\n"
     ]
    }
   ],
   "source": [
    "test_carpark_id = \"U58\"\n",
    "test_timestamp_str = '2025-03-29 13:00:00'\n",
    "prediction = predict_availability(test_carpark_id, test_timestamp_str)\n",
    "print(f\"Predicted availability for {test_carpark_id} at {test_timestamp_str}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45639ab-d1bb-4628-85f1-a35b9e1697fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_row_for_carpark(\n",
    "    carpark_id: str,\n",
    "    ts: pd.Timestamp,\n",
    "    recursion_depth: int,\n",
    "    max_depth: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Helper that:\n",
    "      1) Computes lag_24 availability (possibly by recursion).\n",
    "      2) Builds a single-row feature vector for the specified car park & timestamp.\n",
    "    \"\"\"\n",
    "    lag_24_val = get_lag_24_value(\n",
    "        carpark_id, ts,\n",
    "        recursion_depth=recursion_depth,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    return build_feature_vector(carpark_id, ts, lag_24_val)\n",
    "\n",
    "\n",
    "def predict_multiple_carparks_same_timestamp(\n",
    "    carpark_ids: list[str],\n",
    "    ts_str: str,\n",
    "    recursion_depth: int = 0,\n",
    "    max_depth: int = 1\n",
    ") -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Predicts availability for multiple car parks at a single timestamp,\n",
    "    in one batch, without writing an explicit loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    carpark_ids : list of str\n",
    "        Car park IDs for which to predict availability.\n",
    "    ts_str : str\n",
    "        Timestamp string (e.g., \"2025-03-31 10:00:00\").\n",
    "    recursion_depth : int\n",
    "        Current recursion depth for lag_24 lookups (default=0).\n",
    "    max_depth : int\n",
    "        Maximum recursion depth for lag_24 lookups (default=1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping of carpark_id -> predicted availability at the given timestamp.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    ts = pd.to_datetime(ts_str)\n",
    "\n",
    "    # 1) Build a list of single-row DataFrames (one per car park),\n",
    "    #    using map instead of a manual loop.\n",
    "    feature_dfs = list(\n",
    "        map(\n",
    "            lambda cp_id: _build_row_for_carpark(cp_id, ts, recursion_depth, max_depth),\n",
    "            carpark_ids\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2) Concatenate into one DataFrame for a single model.predict() call\n",
    "    X_batch = pd.concat(feature_dfs, ignore_index=True)\n",
    "\n",
    "    # 3) Batch prediction\n",
    "    preds = model.predict(X_batch)\n",
    "    \n",
    "     # 4) Round to int\n",
    "    rounded_preds = [int(round(float(x))) for x in preds]\n",
    "\n",
    "    # 5) Build dict from carpark_ids & predictions\n",
    "    end_time = time.time()  # End timer\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    print(f\"Prediction took {elapsed:.4f} seconds to process {len(carpark_ids)} carparks.\")\n",
    "    return dict(zip(carpark_ids, rounded_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc1fa041-45b2-41ce-b39d-3059b14e358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 13.3742 seconds to process 5 carparks.\n",
      "{'A11': 197, 'U58': 573, '9': 141, 'B20': 179, 'BJ1': 193}\n"
     ]
    }
   ],
   "source": [
    "print(predict_multiple_carparks_same_timestamp(carpark_ids, test_timestamp_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a7524-ad21-4b69-88d6-d9aa8f1dc489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
